{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x26161b3a640>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import Dataset\n",
    "\n",
    "ratings = Dataset.load_builtin('ml-100k')\n",
    "ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x26161b29b80>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.dataset import DatasetAutoFolds\n",
    "\n",
    "def load_ratings_from_surprise() -> DatasetAutoFolds:\n",
    "    ratings = Dataset.load_builtin('ml-100k')\n",
    "    return ratings\n",
    "\n",
    "load_ratings_from_surprise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x26161b3a580>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data(from_surprise : bool = True) -> DatasetAutoFolds:\n",
    "    data = load_ratings_from_surprise() if from_surprise else load_ratings_from_file()\n",
    "    return data\n",
    "\n",
    "data = get_data(from_surprise=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN AND TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.trainset.Trainset at 0x26161a92670>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "\n",
    "model = SVD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x26161a8eaf0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x2617b366310>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.trainset import Trainset\n",
    "from  surprise.prediction_algorithms.algo_base import AlgoBase\n",
    "\n",
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "\n",
    "\n",
    "def get_trained_model(model_class: AlgoBase, model_kwargs: dict, train_set: Trainset) -> AlgoBase:\n",
    "    model = model_class(sim_options = model_kwargs)\n",
    "    model.fit(train_set)\n",
    "    return model\n",
    "\n",
    "model_kwargs = {'sim_options': {'user_based': False, 'name': 'pearson'}}\n",
    "get_trained_model(KNNBasic, {'user_based': False, 'name': 'pearson'}, train)\n",
    "# {'sim_options': {'user_based': False, 'name': 'pearson'}} - **kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Prediction(uid='907', iid='143', r_ui=5.0, est=4.933808951619199, details={'was_impossible': False}),\n",
       " Prediction(uid='371', iid='210', r_ui=4.0, est=4.078362962844308, details={'was_impossible': False}),\n",
       " Prediction(uid='218', iid='42', r_ui=4.0, est=3.595649012872151, details={'was_impossible': False}),\n",
       " Prediction(uid='829', iid='170', r_ui=4.0, est=4.0427760496270775, details={'was_impossible': False}),\n",
       " Prediction(uid='733', iid='277', r_ui=1.0, est=2.8749039859518057, details={'was_impossible': False}),\n",
       " Prediction(uid='363', iid='1512', r_ui=1.0, est=3.3366097673346116, details={'was_impossible': False}),\n",
       " Prediction(uid='193', iid='487', r_ui=5.0, est=3.800634691159829, details={'was_impossible': False}),\n",
       " Prediction(uid='808', iid='313', r_ui=5.0, est=4.727353848738377, details={'was_impossible': False}),\n",
       " Prediction(uid='557', iid='682', r_ui=2.0, est=3.0444185980429905, details={'was_impossible': False}),\n",
       " Prediction(uid='774', iid='196', r_ui=3.0, est=2.5511704830751993, details={'was_impossible': False})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.test(test)\n",
    "predictions[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9360598063394577"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from surprise import accuracy\n",
    "\n",
    "accuracy.rmse(predictions=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.7367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7366677482366707"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.mae(predictions=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import accuracy\n",
    "\n",
    "def evaluate_model(model: AlgoBase, test_set: [(int, int, float)]) -> dict:\n",
    "    predictions = model.test(test_set)\n",
    "    metrics_dict = {}\n",
    "    metrics_dict['RMSE'] = accuracy.rmse(predictions, verbose=False)\n",
    "    metrics_dict['MAE'] = accuracy.rmse(predictions, verbose=False)\n",
    "    return metrics_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RMSE': 0.980150596704479, 'MAE': 0.980150596704479}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "\n",
    "def train_and_evalute_model_pipeline(model_class: AlgoBase, model_kwargs: dict = {},\n",
    "                                     from_surprise: bool = True,\n",
    "                                     test_size: float = 0.2) -> (AlgoBase, dict):\n",
    "    data = get_data(from_surprise)\n",
    "    train_set, test_set = train_test_split(data, test_size, random_state=42)\n",
    "    model = get_trained_model(model_class, model_kwargs, train_set)\n",
    "    metrics_dict = evaluate_model(model, test_set)\n",
    "    return model, metrics_dict\n",
    "\n",
    "my_model, metrics_dict = train_and_evalute_model_pipeline(KNNBasic)\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x2617b366af0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_trained_model(KNNBasic, {'user_based': False, 'name': 'pearson'}, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BENCHMARKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNN user based cosine': {'RMSE': 1.0193536815834319,\n",
       "  'MAE': 1.0193536815834319},\n",
       " 'KNN user based pearson': {'RMSE': 1.0150350905205965,\n",
       "  'MAE': 1.0150350905205965},\n",
       " 'KNN item based cosine': {'RMSE': 1.0264295933767333,\n",
       "  'MAE': 1.0264295933767333},\n",
       " 'KNN item based pearson': {'RMSE': 1.041104054968961,\n",
       "  'MAE': 1.041104054968961}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "\n",
    "benchmark_dict = {}\n",
    "\n",
    "model_kwargs = {'user_based': True, 'name': 'cosine'}\n",
    "knn, metrics_dict = train_and_evalute_model_pipeline(KNNBasic, model_kwargs)\n",
    "benchmark_dict['KNN user based cosine'] = metrics_dict\n",
    "\n",
    "model_kwargs = {'user_based': True, 'name': 'pearson'}\n",
    "knn, metrics_dict = train_and_evalute_model_pipeline(KNNBasic, model_kwargs)\n",
    "benchmark_dict['KNN user based pearson'] = metrics_dict\n",
    "\n",
    "model_kwargs = {'user_based': False, 'name': 'cosine'}\n",
    "knn, metrics_dict = train_and_evalute_model_pipeline(KNNBasic, model_kwargs)\n",
    "benchmark_dict['KNN item based cosine'] = metrics_dict\n",
    "\n",
    "model_kwargs = {'user_based': False, 'name': 'pearson'}\n",
    "knn, metrics_dict = train_and_evalute_model_pipeline(KNNBasic, model_kwargs)\n",
    "benchmark_dict['KNN item based pearson'] = metrics_dict\n",
    "\n",
    "\n",
    "benchmark_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNN user based with cosine similarity': {'RMSE': 1.0193536815834319,\n",
       "  'MAE': 1.0193536815834319},\n",
       " 'KNN user based with pearson similarity': {'RMSE': 1.0150350905205965,\n",
       "  'MAE': 1.0150350905205965}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_dict = {}\n",
    "\n",
    "model_dict_list = [\n",
    "    {\n",
    "        'model_name' : 'KNN user based with cosine similarity',\n",
    "        'model_class' : KNNBasic,\n",
    "        'model_kwargs' : {'user_based': True, 'name': 'cosine'}\n",
    "    },\n",
    "    {\n",
    "        'model_name' : 'KNN user based with pearson similarity',\n",
    "        'model_class' : KNNBasic,\n",
    "        'model_kwargs' : {'user_based': True, 'name': 'pearson'}\n",
    "    },\n",
    "]\n",
    "\n",
    "for model_dict in model_dict_list:\n",
    "    model, metrics_dict = train_and_evalute_model_pipeline(\n",
    "        model_dict['model_class'], model_dict['model_kwargs'])\n",
    "    benchmark_dict[model_dict['model_name']] = metrics_dict\n",
    "    model_dict['fitted_model'] = model\n",
    "    \n",
    "benchmark_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0096  1.0078  1.0093  1.0107  1.0207  1.0116  0.0046  \n",
      "MAE (testset)     0.8014  0.8008  0.8030  0.8043  0.8072  0.8033  0.0023  \n",
      "Fit time          5.57    5.11    6.42    6.08    5.39    5.71    0.48    \n",
      "Test time         6.13    7.45    7.09    6.39    6.77    6.77    0.47    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.00958923, 1.00780283, 1.00932833, 1.01068972, 1.02069169]),\n",
       " 'test_mae': array([0.80138181, 0.80082149, 0.80297348, 0.80428877, 0.80722312]),\n",
       " 'fit_time': (5.567511796951294,\n",
       "  5.105734825134277,\n",
       "  6.415756464004517,\n",
       "  6.083662748336792,\n",
       "  5.385116815567017),\n",
       " 'test_time': (6.132904767990112,\n",
       "  7.446448802947998,\n",
       "  7.088389158248901,\n",
       "  6.391512632369995,\n",
       "  6.771937847137451)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "cross_validate(model, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVDpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import NMF\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import NormalPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_rmse': array([1.51764022, 1.50631212, 1.5262772 , 1.51479557, 1.51865728]), 'test_mae': array([1.2154921 , 1.20741847, 1.22411177, 1.21469814, 1.2162414 ]), 'fit_time': (0.2735099792480469, 0.35023951530456543, 0.3042285442352295, 0.2512531280517578, 0.28328633308410645), 'test_time': (0.4212214946746826, 0.2668466567993164, 0.4876401424407959, 0.40679097175598145, 0.25433945655822754)}\n"
     ]
    }
   ],
   "source": [
    "algo = NormalPredictor()\n",
    "perf = cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5)\n",
    "print(perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVDpp\n",
    "algo = SVDpp()\n",
    "perf = cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVD++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import NMF\n",
    "algo = NMF()\n",
    "perf = cross_validate(algo, df, measures=['RMSE', 'MAE'], cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Recsys",
   "language": "python",
   "name": "recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
